{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Drive\n",
        "\n"
      ],
      "metadata": {
        "id": "9ootaiqHPYHm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-WWUtz-gk0X",
        "outputId": "7b86eb28-cbba-4fd7-ab9d-f215a535530f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Librerie"
      ],
      "metadata": {
        "id": "moEgX1zhPbMM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "import csv\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix, classification_report\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix, classification_report\n",
        "from tabulate import tabulate\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "import re\n",
        "import logging\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import random\n",
        "import gensim\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "%matplotlib inline\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.utils.class_weight import compute_class_weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLgIP2yTg-8n",
        "outputId": "3be6e580-f7b1-4403-eafe-60a0ecbb713a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Caricamento del dataset"
      ],
      "metadata": {
        "id": "WEhLrmYNPd10"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_csv('/content/drive/MyDrive/unisadataforce/train_set.csv')\n",
        "df_test = pd.read_csv('/content/drive/MyDrive/unisadataforce/new_test.csv')"
      ],
      "metadata": {
        "id": "ieopIUVChByQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre-processing"
      ],
      "metadata": {
        "id": "izRt_0YpPh5p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
        "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "        text: a string\n",
        "\n",
        "        return: modified initial string\n",
        "    \"\"\"\n",
        "    text = BeautifulSoup(text, \"lxml\").text # HTML decoding\n",
        "    text = text.lower() # lowercase text\n",
        "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
        "    text = BAD_SYMBOLS_RE.sub('', text) # delete symbols which are in BAD_SYMBOLS_RE from text\n",
        "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # delete stopwors from text\n",
        "    return text\n",
        "\n",
        "df_train['Text'] = df_train['Text'].apply(clean_text)\n",
        "df_test[\"Text\"] = df_test[\"Text\"].apply(clean_text)"
      ],
      "metadata": {
        "id": "AV5KncgLhLRA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modello"
      ],
      "metadata": {
        "id": "mW_r48Y7PmLL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.multiclass import OneVsOneClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.multiclass import OutputCodeClassifier\n",
        "from sklearn.linear_model import RidgeClassifierCV\n",
        "from sklearn.linear_model import PassiveAggressiveClassifier\n",
        "\n",
        "PA = Pipeline([('vect', CountVectorizer()),\n",
        "               ('tfidf', TfidfTransformer()),\n",
        "               ('rf', PassiveAggressiveClassifier(max_iter=1000, random_state=0,tol=1e-3))])\n",
        "\n",
        "PA.fit(df_train[\"Text\"]+df_train[\"Citations\"], df_train[\"Directory code\"])\n",
        "pred = PA.predict(df_test[\"Text\"]+df_test[\"Citations\"])"
      ],
      "metadata": {
        "id": "1pk0sQYihOMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Crezione csv"
      ],
      "metadata": {
        "id": "Jdq5HqnyPo-u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_predictions = pd.DataFrame({\n",
        "    \"label\": pred,\n",
        "})\n",
        "df_predictions.to_csv(\"/content/drive/MyDrive/unisadataforce/day_2/Consegna Rosaria/passive_aggressive.csv\", index=False)"
      ],
      "metadata": {
        "id": "SXP4o3DxhQE_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}